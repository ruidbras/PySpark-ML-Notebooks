{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Methods Consulting Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've been hired by a dog food company to try to predict why some batches of their dog food are spoiling much quicker than intended! Unfortunately this Dog Food company hasn't upgraded to the latest machinery, meaning that the amounts of the five preservative chemicals they are using can vary a lot, but which is the chemical that has the strongest effect? The dog food company first mixes up a batch of preservative that contains 4 different preservative chemicals (A,B,C,D) and then is completed with a \"filler\" chemical. The food scientists beelive one of the A,B,C, or D preservatives is causing the problem, but need your help to figure out which one!\n",
    "Use Machine Learning with RF to find out which parameter had the most predicitive power, thus finding out which chemical causes the early spoiling! So create a model and then find out how you can decide which chemical is the problem!\n",
    "\n",
    "* Pres_A : Percentage of preservative A in the mix\n",
    "* Pres_B : Percentage of preservative B in the mix\n",
    "* Pres_C : Percentage of preservative C in the mix\n",
    "* Pres_D : Percentage of preservative D in the mix\n",
    "* Spoiled: Label indicating whether or not the dog food batch was spoiled.\n",
    "___\n",
    "\n",
    "**Think carefully about what this problem is really asking you to solve. While we will use Machine Learning to solve this, it won't be with your typical train/test split workflow. If this confuses you, skip ahead to the solution code along walk-through!**\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing is starting a new spark session. Let's call it dogfood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('dogfood').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is reading the data, which is in a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('input data/dog_food.csv', header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can look at some of the values of these 4 columns and label in each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(A=4, B=2, C=12.0, D=3, Spoiled=1.0)\n",
      "-------\n",
      "\n",
      "\n",
      "Row(A=5, B=6, C=12.0, D=7, Spoiled=1.0)\n",
      "-------\n",
      "\n",
      "\n",
      "Row(A=6, B=2, C=13.0, D=6, Spoiled=1.0)\n",
      "-------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in df.head(3):\n",
    "    print(s)\n",
    "    print('-------')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the columns again tu use them in the VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'Spoiled']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that will be used requires our data to be in a given format so let's use the VectorAssembler in order to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['A', 'B', 'C', 'D'],\n",
    "                               outputCol='features')\n",
    "output = assembler.transform(df)\n",
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there is a features vector and a Spoiled label the model can be created.\n",
    "\n",
    "A RandomForestClassifier will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (RandomForestClassifier,\n",
    "                                           DecisionTreeClassifier)\n",
    "\n",
    "rfc = RandomForestClassifier(labelCol='Spoiled', featuresCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting the features vector and the label column the model can be trained using the fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = output.select('features', 'Spoiled')\n",
    "rfc_model = rfc.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was asked, the chemical with more influence can be obtained using featureImportances, wich reaturns a SparseVector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 0.0196, 1: 0.0212, 2: 0.9185, 3: 0.0406})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above cell it is easy to conclude that number 2 (which corresponds to chemical C) is by far the most important feature.\n",
    "\n",
    "Nevertheless, a plot of these feature importances is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.barplot(x=rfc_model.featureImportances.indices,\n",
    "            y=rfc_model.featureImportances.values,\n",
    "            palette='viridis')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models can be used in multiple ways and this was just an alternative approach as teh goal was to check which feature drives the causation of whether or not the dog food is spoiled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
